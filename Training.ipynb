{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-12-18T17:35:18.005786",
     "start_time": "2016-12-18T17:35:18.001786"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "import ast\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-12-18T17:35:20.748943",
     "start_time": "2016-12-18T17:35:20.744943"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-12-18T17:35:34.915753",
     "start_time": "2016-12-18T17:35:34.710742"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-12-18T17:15:31.479921",
     "start_time": "2016-12-18T17:15:31.468920"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import collections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-12-18T17:15:31.569926",
     "start_time": "2016-12-18T17:15:31.485921"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-12-18T17:15:31.652931",
     "start_time": "2016-12-18T17:15:31.573926"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "features_key = \"features\"\n",
    "label_key = \"label\"\n",
    "csv_file_path = 'num_recognition_training_data.csv'\n",
    "\n",
    "def get_csv_data():\n",
    "        train_labels = []\n",
    "        train_features = []\n",
    "        with open(csv_file_path) as csvfile:\n",
    "            data_reader = csv.reader(csvfile, delimiter=',')\n",
    "            for row in data_reader:\n",
    "                train_labels.append(row[0])\n",
    "                features = ast.literal_eval(row[1])\n",
    "                train_features.append(features)\n",
    "\n",
    "        return {\n",
    "            label_key: train_labels,\n",
    "            features_key: train_features\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-12-18T17:22:26.911682",
     "start_time": "2016-12-18T17:22:26.597664"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "labels, features = get_csv_data().values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-12-18T17:39:16.176409",
     "start_time": "2016-12-18T17:39:16.169408"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def train_data(labels, features, solver='SVC', **kwargs):\n",
    "    \n",
    "    if solver == 'SVC':\n",
    "        classifier = svm.SVC(**kwargs)\n",
    "    else:\n",
    "        print('using other than SVC')\n",
    "        classifier = MLPClassifier()\n",
    "        \n",
    "    classifier.fit(labels, features)\n",
    "    \n",
    "    return classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-12-18T17:34:13.721109",
     "start_time": "2016-12-18T17:34:13.715109"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def cross_validate(classifier, to_predict_features, to_predict_labels):\n",
    "    # make prediction\n",
    "    prediction = classifier.predict(to_predict_features)\n",
    "    \n",
    "    # check validity\n",
    "    return confusion_matrix(to_predict_labels, prediction), \\\n",
    "        classification_report(to_predict_labels, prediction), \\\n",
    "        f1_score(to_predict_labels, prediction, average='weighted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-12-18T17:46:50.830414",
     "start_time": "2016-12-18T17:46:50.749409"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def make_model(labels, features):\n",
    "    # convert to numpy array\n",
    "    labels = np.array(labels, dtype='uint8')\n",
    "    features = np.array(features, dtype='float_')\n",
    "    \n",
    "    # create random state to maintain randomness\n",
    "    rs = np.random.RandomState(seed=1234567890)\n",
    "    \n",
    "    # randomize the data\n",
    "    rs.shuffle(labels)\n",
    "    rs.shuffle(features)\n",
    "\n",
    "    total_test = len(labels) * 5 // 6\n",
    "    \n",
    "    # check occurences\n",
    "    test_occ = sorted(collections.Counter(labels[:total_test]).items())\n",
    "    cv_occ = sorted(collections.Counter(labels[total_test:]).items())\n",
    "    \n",
    "    print('Train labels: {}\\nCV    labels: {}\\n\\n'.format(test_occ, cv_occ))\n",
    "    \n",
    "    classifier = train_data(features[:total_test], labels[:total_test], solver='NN')\n",
    "    matrix, report, f1_score = cross_validate(classifier, features[total_test:], labels[total_test:])\n",
    "    print(matrix)\n",
    "    print('\\n')\n",
    "    print(report)\n",
    "    \n",
    "    costs = np.linspace(10, 100, num=5) \n",
    "    gammas = np.linspace(0.05, 0.06, num=5)\n",
    "    scores = []\n",
    "    \n",
    "#     for cost in costs:\n",
    "#         for gamma in gammas:\n",
    "#             classifier = train_data(features[:total_test], labels[:total_test], solver='NN', C=cost, gamma=gamma)\n",
    "\n",
    "#             matrix, report, f1_score = cross_validate(classifier, features[total_test:], labels[total_test:])\n",
    "#             scores.append((cost, gamma, f1_score))\n",
    "# #             print('Cost: {}\\nGamma: {}\\nScore: {}\\n\\n'.format(cost, gamma, f1_score))\n",
    "# #             print(matrix)\n",
    "# #             print('\\n')\n",
    "# #             print(report)\n",
    "    \n",
    "#     fig = plt.figure()\n",
    "#     ax = fig.add_subplot(111, projection='3d')\n",
    "    \n",
    "#     x, y, z = zip(*scores)\n",
    "# #     print(x)\n",
    "# #     print(y)\n",
    "#     print(z)\n",
    "    \n",
    "#     ax.scatter(x, y, z, c='r', marker='o')\n",
    "\n",
    "#     ax.set_xlabel('C')\n",
    "#     ax.set_ylabel('Gamma')\n",
    "#     ax.set_zlabel('F1_score')\n",
    "\n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-12-18T17:46:54.259610",
     "start_time": "2016-12-18T17:46:52.403503"
    },
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train labels: [(0, 64), (1, 32), (2, 80), (3, 48), (4, 66), (5, 52), (6, 61), (7, 86), (8, 87), (9, 90)]\n",
      "CV    labels: [(0, 13), (1, 7), (2, 22), (3, 6), (4, 9), (5, 16), (6, 13), (7, 18), (8, 17), (9, 13)]\n",
      "\n",
      "\n",
      "using other than SVC\n",
      "[[1 0 2 1 1 0 1 2 3 2]\n",
      " [1 1 1 0 1 0 0 1 0 2]\n",
      " [2 0 2 0 1 2 3 3 2 7]\n",
      " [1 0 2 1 1 0 1 0 0 0]\n",
      " [1 0 0 1 1 1 1 1 1 2]\n",
      " [2 0 0 1 1 0 3 5 2 2]\n",
      " [1 0 2 2 0 0 1 4 1 2]\n",
      " [1 3 4 0 0 5 0 3 1 1]\n",
      " [2 0 1 0 4 1 3 2 3 1]\n",
      " [2 1 0 0 5 0 0 1 1 3]]\n",
      "\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.07      0.08      0.07        13\n",
      "          1       0.20      0.14      0.17         7\n",
      "          2       0.14      0.09      0.11        22\n",
      "          3       0.17      0.17      0.17         6\n",
      "          4       0.07      0.11      0.08         9\n",
      "          5       0.00      0.00      0.00        16\n",
      "          6       0.08      0.08      0.08        13\n",
      "          7       0.14      0.17      0.15        18\n",
      "          8       0.21      0.18      0.19        17\n",
      "          9       0.14      0.23      0.17        13\n",
      "\n",
      "avg / total       0.12      0.12      0.12       134\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\envs\\sandbox\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:563: ConvergenceWarning: Stochastic Optimizer: Maximum iterations reached and the optimization hasn't converged yet.\n",
      "  % (), ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "make_model(labels, features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
