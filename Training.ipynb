{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-12-18T17:35:18.005786",
     "start_time": "2016-12-18T17:35:18.001786"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "import ast\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-12-18T17:35:20.748943",
     "start_time": "2016-12-18T17:35:20.744943"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-12-18T17:35:34.915753",
     "start_time": "2016-12-18T17:35:34.710742"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-12-18T17:15:31.479921",
     "start_time": "2016-12-18T17:15:31.468920"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import collections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-12-18T17:15:31.569926",
     "start_time": "2016-12-18T17:15:31.485921"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-12-18T17:15:31.652931",
     "start_time": "2016-12-18T17:15:31.573926"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "features_key = \"features\"\n",
    "label_key = \"label\"\n",
    "csv_file_path = 'num_recognition_training_data.csv'\n",
    "\n",
    "def get_csv_data():\n",
    "        train_labels = []\n",
    "        train_features = []\n",
    "        with open(csv_file_path) as csvfile:\n",
    "            data_reader = csv.reader(csvfile, delimiter=',')\n",
    "            for row in data_reader:\n",
    "                train_labels.append(row[0])\n",
    "                features = ast.literal_eval(row[1])\n",
    "                train_features.append(features)\n",
    "\n",
    "        return {\n",
    "            label_key: train_labels,\n",
    "            features_key: train_features\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-12-18T17:22:26.911682",
     "start_time": "2016-12-18T17:22:26.597664"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "labels, features = get_csv_data().values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-12-18T19:05:31.189403",
     "start_time": "2016-12-18T19:05:31.179402"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def train_data(labels, features, solver='svm', **kwargs):\n",
    "    \n",
    "    if solver == 'svm':\n",
    "        classifier = svm.SVC(**kwargs)\n",
    "    else:\n",
    "        print('using other than SVC')\n",
    "        classifier = MLPClassifier()\n",
    "        \n",
    "    classifier.fit(labels, features)\n",
    "    \n",
    "    return classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-12-18T19:23:57.286668",
     "start_time": "2016-12-18T19:23:57.280667"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def cross_validate(classifier, to_predict_features, to_predict_labels):\n",
    "    # make prediction\n",
    "    prediction = classifier.predict(to_predict_features)\n",
    "    \n",
    "    # check validity\n",
    "    return confusion_matrix(to_predict_labels, prediction), \\\n",
    "        classification_report(to_predict_labels, prediction), \\\n",
    "        f1_score(to_predict_labels, prediction, average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-12-18T19:44:13.073207",
     "start_time": "2016-12-18T19:44:12.954200"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def make_model(labels, features, solver='svm'):\n",
    "    # convert to numpy array\n",
    "    labels = np.array(labels, dtype='uint8')\n",
    "    features = np.array(features, dtype='float_')\n",
    "    \n",
    "    # this one to converts everything become 2 class\n",
    "    labels = (labels==6).astype(int)\n",
    "    \n",
    "    # create random state to maintain randomness\n",
    "    rs = np.random.RandomState(seed=46542)\n",
    "    \n",
    "    # randomize the data\n",
    "    rs.shuffle(labels)\n",
    "    rs.shuffle(features)\n",
    "\n",
    "    total_test = len(labels) // 2\n",
    "    \n",
    "    # check occurences\n",
    "    test_occ = sorted(collections.Counter(labels[:total_test]).items())\n",
    "    cv_occ = sorted(collections.Counter(labels[total_test:]).items())\n",
    "    \n",
    "    print('Train labels: {}\\nCV    labels: {}\\n\\n'.format(test_occ, cv_occ))\n",
    "    \n",
    "    # svm\n",
    "    if solver == 'svm':\n",
    "        costs = np.linspace(10, 100, num=2) \n",
    "        gammas = np.linspace(0.001, 0.1, num=50)\n",
    "        scores = []\n",
    "        \n",
    "        for cost in costs:\n",
    "            for gamma in gammas:\n",
    "                classifier = train_data(features[:total_test], labels[:total_test], solver='svm', C=cost, gamma=gamma)\n",
    "\n",
    "                matrix, report, f1_score = cross_validate(classifier, features[total_test:], labels[total_test:])\n",
    "                scores.append((cost, gamma, f1_score))\n",
    "                print('Cost: {}\\nGamma: {}\\nScore: {}\\n\\n'.format(cost, gamma, f1_score))\n",
    "#                 print(matrix)\n",
    "#                 print('\\n')\n",
    "                print(report)\n",
    "    \n",
    "        fig = plt.figure()\n",
    "        ax = fig.add_subplot(111, projection='3d')\n",
    "    \n",
    "        x, y, z = zip(*scores)\n",
    "\n",
    "        ax.scatter(x, y, z, c='r', marker='o')\n",
    "\n",
    "        ax.set_xlabel('C')\n",
    "        ax.set_ylabel('Gamma')\n",
    "        ax.set_zlabel('F1_score')\n",
    "\n",
    "        plt.show()\n",
    "        \n",
    "    else:\n",
    "        # Neural network\n",
    "        classifier = train_data(features[:total_test], labels[:total_test], solver='nn')\n",
    "        matrix, report, f1_score = cross_validate(classifier, features[total_test:], labels[total_test:])\n",
    "        print(matrix)\n",
    "        print('\\n')\n",
    "        print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-12-18T19:44:51.779421",
     "start_time": "2016-12-18T19:44:13.514232"
    },
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train labels: [(0, 366), (1, 34)]\n",
      "CV    labels: [(0, 360), (1, 40)]\n",
      "\n",
      "\n",
      "Cost: 10.0\n",
      "Gamma: 0.001\n",
      "Score: 0.4736842105263158\n",
      "\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.90      1.00      0.95       360\n",
      "          1       0.00      0.00      0.00        40\n",
      "\n",
      "avg / total       0.81      0.90      0.85       400\n",
      "\n",
      "Cost: 10.0\n",
      "Gamma: 0.0030204081632653063\n",
      "Score: 0.4736842105263158\n",
      "\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.90      1.00      0.95       360\n",
      "          1       0.00      0.00      0.00        40\n",
      "\n",
      "avg / total       0.81      0.90      0.85       400\n",
      "\n",
      "Cost: 10.0\n",
      "Gamma: 0.0050408163265306125\n",
      "Score: 0.4736842105263158\n",
      "\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.90      1.00      0.95       360\n",
      "          1       0.00      0.00      0.00        40\n",
      "\n",
      "avg / total       0.81      0.90      0.85       400\n",
      "\n",
      "Cost: 10.0\n",
      "Gamma: 0.007061224489795919\n",
      "Score: 0.4736842105263158\n",
      "\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.90      1.00      0.95       360\n",
      "          1       0.00      0.00      0.00        40\n",
      "\n",
      "avg / total       0.81      0.90      0.85       400\n",
      "\n",
      "Cost: 10.0\n",
      "Gamma: 0.009081632653061226\n",
      "Score: 0.4736842105263158\n",
      "\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.90      1.00      0.95       360\n",
      "          1       0.00      0.00      0.00        40\n",
      "\n",
      "avg / total       0.81      0.90      0.85       400\n",
      "\n",
      "Cost: 10.0\n",
      "Gamma: 0.011102040816326531\n",
      "Score: 0.4736842105263158\n",
      "\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.90      1.00      0.95       360\n",
      "          1       0.00      0.00      0.00        40\n",
      "\n",
      "avg / total       0.81      0.90      0.85       400\n",
      "\n",
      "Cost: 10.0\n",
      "Gamma: 0.013122448979591837\n",
      "Score: 0.4736842105263158\n",
      "\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.90      1.00      0.95       360\n",
      "          1       0.00      0.00      0.00        40\n",
      "\n",
      "avg / total       0.81      0.90      0.85       400\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\envs\\sandbox\\lib\\site-packages\\sklearn\\metrics\\classification.py:1113: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "D:\\Anaconda\\envs\\sandbox\\lib\\site-packages\\sklearn\\metrics\\classification.py:1113: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost: 10.0\n",
      "Gamma: 0.015142857142857145\n",
      "Score: 0.4736842105263158\n",
      "\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.90      1.00      0.95       360\n",
      "          1       0.00      0.00      0.00        40\n",
      "\n",
      "avg / total       0.81      0.90      0.85       400\n",
      "\n",
      "Cost: 10.0\n",
      "Gamma: 0.01716326530612245\n",
      "Score: 0.49617523271174463\n",
      "\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.90      0.99      0.95       360\n",
      "          1       0.33      0.03      0.05        40\n",
      "\n",
      "avg / total       0.84      0.90      0.86       400\n",
      "\n",
      "Cost: 10.0\n",
      "Gamma: 0.019183673469387756\n",
      "Score: 0.49617523271174463\n",
      "\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.90      0.99      0.95       360\n",
      "          1       0.33      0.03      0.05        40\n",
      "\n",
      "avg / total       0.84      0.90      0.86       400\n",
      "\n",
      "Cost: 10.0\n",
      "Gamma: 0.02120408163265306\n",
      "Score: 0.4949494949494949\n",
      "\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.90      0.99      0.94       360\n",
      "          1       0.25      0.03      0.05        40\n",
      "\n",
      "avg / total       0.84      0.90      0.85       400\n",
      "\n",
      "Cost: 10.0\n",
      "Gamma: 0.02322448979591837\n",
      "Score: 0.4925614116018913\n",
      "\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.90      0.99      0.94       360\n",
      "          1       0.17      0.03      0.04        40\n",
      "\n",
      "avg / total       0.83      0.89      0.85       400\n",
      "\n",
      "Cost: 10.0\n",
      "Gamma: 0.025244897959183676\n",
      "Score: 0.5140007346500522\n",
      "\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.90      0.99      0.94       360\n",
      "          1       0.29      0.05      0.09        40\n",
      "\n",
      "avg / total       0.84      0.89      0.86       400\n",
      "\n",
      "Cost: 10.0\n",
      "Gamma: 0.02726530612244898\n",
      "Score: 0.5093333333333333\n",
      "\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.90      0.98      0.94       360\n",
      "          1       0.20      0.05      0.08        40\n",
      "\n",
      "avg / total       0.83      0.89      0.85       400\n",
      "\n",
      "Cost: 10.0\n",
      "Gamma: 0.02928571428571429\n",
      "Score: 0.5078405193853242\n",
      "\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.90      0.97      0.94       360\n",
      "          1       0.18      0.05      0.08        40\n",
      "\n",
      "avg / total       0.83      0.88      0.85       400\n",
      "\n",
      "Cost: 10.0\n",
      "Gamma: 0.031306122448979595\n",
      "Score: 0.5063759769642122\n",
      "\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.90      0.97      0.94       360\n",
      "          1       0.17      0.05      0.08        40\n",
      "\n",
      "avg / total       0.83      0.88      0.85       400\n",
      "\n",
      "Cost: 10.0\n",
      "Gamma: 0.0333265306122449\n",
      "Score: 0.5049379909575409\n",
      "\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.90      0.97      0.93       360\n",
      "          1       0.15      0.05      0.08        40\n",
      "\n",
      "avg / total       0.83      0.88      0.85       400\n",
      "\n",
      "Cost: 10.0\n",
      "Gamma: 0.035346938775510206\n",
      "Score: 0.5035249726938735\n",
      "\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.90      0.97      0.93       360\n",
      "          1       0.14      0.05      0.07        40\n",
      "\n",
      "avg / total       0.83      0.88      0.85       400\n",
      "\n",
      "Cost: 10.0\n",
      "Gamma: 0.03736734693877551\n",
      "Score: 0.5021354484441732\n",
      "\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.90      0.96      0.93       360\n",
      "          1       0.13      0.05      0.07        40\n",
      "\n",
      "avg / total       0.82      0.87      0.85       400\n",
      "\n",
      "Cost: 10.0\n",
      "Gamma: 0.03938775510204082\n",
      "Score: 0.5021354484441732\n",
      "\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.90      0.96      0.93       360\n",
      "          1       0.13      0.05      0.07        40\n",
      "\n",
      "avg / total       0.82      0.87      0.85       400\n",
      "\n",
      "Cost: 10.0\n",
      "Gamma: 0.04140816326530612\n",
      "Score: 0.5063759769642122\n",
      "\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.90      0.97      0.94       360\n",
      "          1       0.17      0.05      0.08        40\n",
      "\n",
      "avg / total       0.83      0.88      0.85       400\n",
      "\n",
      "Cost: 10.0\n",
      "Gamma: 0.043428571428571434\n",
      "Score: 0.5049379909575409\n",
      "\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.90      0.97      0.93       360\n",
      "          1       0.15      0.05      0.08        40\n",
      "\n",
      "avg / total       0.83      0.88      0.85       400\n",
      "\n",
      "Cost: 10.0\n",
      "Gamma: 0.04544897959183674\n",
      "Score: 0.5049379909575409\n",
      "\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.90      0.97      0.93       360\n",
      "          1       0.15      0.05      0.08        40\n",
      "\n",
      "avg / total       0.83      0.88      0.85       400\n",
      "\n",
      "Cost: 10.0\n",
      "Gamma: 0.047469387755102045\n",
      "Score: 0.5049379909575409\n",
      "\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.90      0.97      0.93       360\n",
      "          1       0.15      0.05      0.08        40\n",
      "\n",
      "avg / total       0.83      0.88      0.85       400\n",
      "\n",
      "Cost: 10.0\n",
      "Gamma: 0.04948979591836735\n",
      "Score: 0.5049379909575409\n",
      "\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.90      0.97      0.93       360\n",
      "          1       0.15      0.05      0.08        40\n",
      "\n",
      "avg / total       0.83      0.88      0.85       400\n",
      "\n",
      "Cost: 10.0\n",
      "Gamma: 0.051510204081632656\n",
      "Score: 0.5049379909575409\n",
      "\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.90      0.97      0.93       360\n",
      "          1       0.15      0.05      0.08        40\n",
      "\n",
      "avg / total       0.83      0.88      0.85       400\n",
      "\n",
      "Cost: 10.0\n",
      "Gamma: 0.05353061224489796\n",
      "Score: 0.5049379909575409\n",
      "\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.90      0.97      0.93       360\n",
      "          1       0.15      0.05      0.08        40\n",
      "\n",
      "avg / total       0.83      0.88      0.85       400\n",
      "\n",
      "Cost: 10.0\n",
      "Gamma: 0.05555102040816327\n",
      "Score: 0.5035249726938735\n",
      "\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.90      0.97      0.93       360\n",
      "          1       0.14      0.05      0.07        40\n",
      "\n",
      "avg / total       0.83      0.88      0.85       400\n",
      "\n",
      "Cost: 10.0\n",
      "Gamma: 0.05757142857142858\n",
      "Score: 0.5021354484441732\n",
      "\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.90      0.96      0.93       360\n",
      "          1       0.13      0.05      0.07        40\n",
      "\n",
      "avg / total       0.82      0.87      0.85       400\n",
      "\n",
      "Cost: 10.0\n",
      "Gamma: 0.059591836734693884\n",
      "Score: 0.5035249726938735\n",
      "\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.90      0.97      0.93       360\n",
      "          1       0.14      0.05      0.07        40\n",
      "\n",
      "avg / total       0.83      0.88      0.85       400\n",
      "\n",
      "Cost: 10.0\n",
      "Gamma: 0.06161224489795919\n",
      "Score: 0.5035249726938735\n",
      "\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.90      0.97      0.93       360\n",
      "          1       0.14      0.05      0.07        40\n",
      "\n",
      "avg / total       0.83      0.88      0.85       400\n",
      "\n",
      "Cost: 10.0\n",
      "Gamma: 0.0636326530612245\n",
      "Score: 0.5049379909575409\n",
      "\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.90      0.97      0.93       360\n",
      "          1       0.15      0.05      0.08        40\n",
      "\n",
      "avg / total       0.83      0.88      0.85       400\n",
      "\n",
      "Cost: 10.0\n",
      "Gamma: 0.0656530612244898\n",
      "Score: 0.5078405193853242\n",
      "\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.90      0.97      0.94       360\n",
      "          1       0.18      0.05      0.08        40\n",
      "\n",
      "avg / total       0.83      0.88      0.85       400\n",
      "\n",
      "Cost: 10.0\n",
      "Gamma: 0.0676734693877551\n",
      "Score: 0.5078405193853242\n",
      "\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.90      0.97      0.94       360\n",
      "          1       0.18      0.05      0.08        40\n",
      "\n",
      "avg / total       0.83      0.88      0.85       400\n",
      "\n",
      "Cost: 10.0\n",
      "Gamma: 0.06969387755102041\n",
      "Score: 0.5093333333333333\n",
      "\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.90      0.98      0.94       360\n",
      "          1       0.20      0.05      0.08        40\n",
      "\n",
      "avg / total       0.83      0.89      0.85       400\n",
      "\n",
      "Cost: 10.0\n",
      "Gamma: 0.07171428571428572\n",
      "Score: 0.5108562732682953\n",
      "\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.90      0.98      0.94       360\n",
      "          1       0.22      0.05      0.08        40\n",
      "\n",
      "avg / total       0.83      0.89      0.85       400\n",
      "\n",
      "Cost: 10.0\n",
      "Gamma: 0.07373469387755102\n",
      "Score: 0.5108562732682953\n",
      "\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.90      0.98      0.94       360\n",
      "          1       0.22      0.05      0.08        40\n",
      "\n",
      "avg / total       0.83      0.89      0.85       400\n",
      "\n",
      "Cost: 10.0\n",
      "Gamma: 0.07575510204081633\n",
      "Score: 0.5108562732682953\n",
      "\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.90      0.98      0.94       360\n",
      "          1       0.22      0.05      0.08        40\n",
      "\n",
      "avg / total       0.83      0.89      0.85       400\n",
      "\n",
      "Cost: 10.0\n",
      "Gamma: 0.07777551020408163\n",
      "Score: 0.5108562732682953\n",
      "\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.90      0.98      0.94       360\n",
      "          1       0.22      0.05      0.08        40\n",
      "\n",
      "avg / total       0.83      0.89      0.85       400\n",
      "\n",
      "Cost: 10.0\n",
      "Gamma: 0.07979591836734694\n",
      "Score: 0.5108562732682953\n",
      "\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.90      0.98      0.94       360\n",
      "          1       0.22      0.05      0.08        40\n",
      "\n",
      "avg / total       0.83      0.89      0.85       400\n",
      "\n",
      "Cost: 10.0\n",
      "Gamma: 0.08181632653061224\n",
      "Score: 0.5108562732682953\n",
      "\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.90      0.98      0.94       360\n",
      "          1       0.22      0.05      0.08        40\n",
      "\n",
      "avg / total       0.83      0.89      0.85       400\n",
      "\n",
      "Cost: 10.0\n",
      "Gamma: 0.08383673469387756\n",
      "Score: 0.5108562732682953\n",
      "\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.90      0.98      0.94       360\n",
      "          1       0.22      0.05      0.08        40\n",
      "\n",
      "avg / total       0.83      0.89      0.85       400\n",
      "\n",
      "Cost: 10.0\n",
      "Gamma: 0.08585714285714287\n",
      "Score: 0.5108562732682953\n",
      "\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.90      0.98      0.94       360\n",
      "          1       0.22      0.05      0.08        40\n",
      "\n",
      "avg / total       0.83      0.89      0.85       400\n",
      "\n",
      "Cost: 10.0\n",
      "Gamma: 0.08787755102040817\n",
      "Score: 0.5108562732682953\n",
      "\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.90      0.98      0.94       360\n",
      "          1       0.22      0.05      0.08        40\n",
      "\n",
      "avg / total       0.83      0.89      0.85       400\n",
      "\n",
      "Cost: 10.0\n",
      "Gamma: 0.08989795918367348\n",
      "Score: 0.5108562732682953\n",
      "\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.90      0.98      0.94       360\n",
      "          1       0.22      0.05      0.08        40\n",
      "\n",
      "avg / total       0.83      0.89      0.85       400\n",
      "\n",
      "Cost: 10.0\n",
      "Gamma: 0.09191836734693878\n",
      "Score: 0.5108562732682953\n",
      "\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.90      0.98      0.94       360\n",
      "          1       0.22      0.05      0.08        40\n",
      "\n",
      "avg / total       0.83      0.89      0.85       400\n",
      "\n",
      "Cost: 10.0\n",
      "Gamma: 0.09393877551020409\n",
      "Score: 0.5108562732682953\n",
      "\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.90      0.98      0.94       360\n",
      "          1       0.22      0.05      0.08        40\n",
      "\n",
      "avg / total       0.83      0.89      0.85       400\n",
      "\n",
      "Cost: 10.0\n",
      "Gamma: 0.0959591836734694\n",
      "Score: 0.5108562732682953\n",
      "\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.90      0.98      0.94       360\n",
      "          1       0.22      0.05      0.08        40\n",
      "\n",
      "avg / total       0.83      0.89      0.85       400\n",
      "\n",
      "Cost: 10.0\n",
      "Gamma: 0.0979795918367347\n",
      "Score: 0.5108562732682953\n",
      "\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.90      0.98      0.94       360\n",
      "          1       0.22      0.05      0.08        40\n",
      "\n",
      "avg / total       0.83      0.89      0.85       400\n",
      "\n",
      "Cost: 10.0\n",
      "Gamma: 0.1\n",
      "Score: 0.5108562732682953\n",
      "\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.90      0.98      0.94       360\n",
      "          1       0.22      0.05      0.08        40\n",
      "\n",
      "avg / total       0.83      0.89      0.85       400\n",
      "\n",
      "Cost: 100.0\n",
      "Gamma: 0.001\n",
      "Score: 0.4736842105263158\n",
      "\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.90      1.00      0.95       360\n",
      "          1       0.00      0.00      0.00        40\n",
      "\n",
      "avg / total       0.81      0.90      0.85       400\n",
      "\n",
      "Cost: 100.0\n",
      "Gamma: 0.0030204081632653063\n",
      "Score: 0.518999518999519\n",
      "\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.90      0.99      0.95       360\n",
      "          1       0.50      0.05      0.09        40\n",
      "\n",
      "avg / total       0.86      0.90      0.86       400\n",
      "\n",
      "Cost: 100.0\n",
      "Gamma: 0.0050408163265306125\n",
      "Score: 0.5352727948694116\n",
      "\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.91      0.96      0.93       360\n",
      "          1       0.22      0.10      0.14        40\n",
      "\n",
      "avg / total       0.84      0.88      0.85       400\n",
      "\n",
      "Cost: 100.0\n",
      "Gamma: 0.007061224489795919\n",
      "Score: 0.5285844007805406\n",
      "\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.91      0.93      0.92       360\n",
      "          1       0.16      0.12      0.14        40\n",
      "\n",
      "avg / total       0.83      0.85      0.84       400\n",
      "\n",
      "Cost: 100.0\n",
      "Gamma: 0.009081632653061226\n",
      "Score: 0.5071264367816092\n",
      "\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.90      0.91      0.91       360\n",
      "          1       0.11      0.10      0.11        40\n",
      "\n",
      "avg / total       0.82      0.83      0.83       400\n",
      "\n",
      "Cost: 100.0\n",
      "Gamma: 0.011102040816326531\n",
      "Score: 0.5042302096244005\n",
      "\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.90      0.91      0.90       360\n",
      "          1       0.11      0.10      0.10        40\n",
      "\n",
      "avg / total       0.82      0.83      0.82       400\n",
      "\n",
      "Cost: 100.0\n",
      "Gamma: 0.013122448979591837\n",
      "Score: 0.5131281516258042\n",
      "\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.90      0.93      0.91       360\n",
      "          1       0.13      0.10      0.11        40\n",
      "\n",
      "avg / total       0.83      0.84      0.83       400\n",
      "\n",
      "Cost: 100.0\n",
      "Gamma: 0.015142857142857145\n",
      "Score: 0.49902152641878667\n",
      "\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.90      0.93      0.91       360\n",
      "          1       0.10      0.07      0.09        40\n",
      "\n",
      "avg / total       0.82      0.84      0.83       400\n",
      "\n",
      "Cost: 100.0\n",
      "Gamma: 0.01716326530612245\n",
      "Score: 0.5060177917320774\n",
      "\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.90      0.94      0.92       360\n",
      "          1       0.12      0.07      0.09        40\n",
      "\n",
      "avg / total       0.82      0.85      0.84       400\n",
      "\n",
      "Cost: 100.0\n",
      "Gamma: 0.019183673469387756\n",
      "Score: 0.5074728260869565\n",
      "\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.90      0.94      0.92       360\n",
      "          1       0.12      0.07      0.09        40\n",
      "\n",
      "avg / total       0.82      0.85      0.84       400\n",
      "\n",
      "Cost: 100.0\n",
      "Gamma: 0.02120408163265306\n",
      "Score: 0.5119678786131014\n",
      "\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.90      0.95      0.93       360\n",
      "          1       0.14      0.07      0.10        40\n",
      "\n",
      "avg / total       0.83      0.86      0.84       400\n",
      "\n",
      "Cost: 100.0\n",
      "Gamma: 0.02322448979591837\n",
      "Score: 0.5135135135135135\n",
      "\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.90      0.95      0.93       360\n",
      "          1       0.15      0.07      0.10        40\n",
      "\n",
      "avg / total       0.83      0.86      0.84       400\n",
      "\n",
      "Cost: 100.0\n",
      "Gamma: 0.025244897959183676\n",
      "Score: 0.5150849744962145\n",
      "\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.90      0.96      0.93       360\n",
      "          1       0.16      0.07      0.10        40\n",
      "\n",
      "avg / total       0.83      0.87      0.85       400\n",
      "\n",
      "Cost: 100.0\n",
      "Gamma: 0.02726530612244898\n",
      "Score: 0.5135135135135135\n",
      "\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.90      0.95      0.93       360\n",
      "          1       0.15      0.07      0.10        40\n",
      "\n",
      "avg / total       0.83      0.86      0.84       400\n",
      "\n",
      "Cost: 100.0\n",
      "Gamma: 0.02928571428571429\n",
      "Score: 0.5135135135135135\n",
      "\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.90      0.95      0.93       360\n",
      "          1       0.15      0.07      0.10        40\n",
      "\n",
      "avg / total       0.83      0.86      0.84       400\n",
      "\n",
      "Cost: 100.0\n",
      "Gamma: 0.031306122448979595\n",
      "Score: 0.5166837066641882\n",
      "\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.90      0.96      0.93       360\n",
      "          1       0.17      0.07      0.10        40\n",
      "\n",
      "avg / total       0.83      0.87      0.85       400\n",
      "\n",
      "Cost: 100.0\n",
      "Gamma: 0.0333265306122449\n",
      "Score: 0.5166837066641882\n",
      "\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.90      0.96      0.93       360\n",
      "          1       0.17      0.07      0.10        40\n",
      "\n",
      "avg / total       0.83      0.87      0.85       400\n",
      "\n",
      "Cost: 100.0\n",
      "Gamma: 0.035346938775510206\n",
      "Score: 0.49942150126325235\n",
      "\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.90      0.96      0.93       360\n",
      "          1       0.12      0.05      0.07        40\n",
      "\n",
      "avg / total       0.82      0.87      0.84       400\n",
      "\n",
      "Cost: 100.0\n",
      "Gamma: 0.03736734693877551\n",
      "Score: 0.500768049155146\n",
      "\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.90      0.96      0.93       360\n",
      "          1       0.12      0.05      0.07        40\n",
      "\n",
      "avg / total       0.82      0.87      0.84       400\n",
      "\n",
      "Cost: 100.0\n",
      "Gamma: 0.03938775510204082\n",
      "Score: 0.5021354484441732\n",
      "\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.90      0.96      0.93       360\n",
      "          1       0.13      0.05      0.07        40\n",
      "\n",
      "avg / total       0.82      0.87      0.85       400\n",
      "\n",
      "Cost: 100.0\n",
      "Gamma: 0.04140816326530612\n",
      "Score: 0.5021354484441732\n",
      "\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.90      0.96      0.93       360\n",
      "          1       0.13      0.05      0.07        40\n",
      "\n",
      "avg / total       0.82      0.87      0.85       400\n",
      "\n",
      "Cost: 100.0\n",
      "Gamma: 0.043428571428571434\n",
      "Score: 0.5021354484441732\n",
      "\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.90      0.96      0.93       360\n",
      "          1       0.13      0.05      0.07        40\n",
      "\n",
      "avg / total       0.82      0.87      0.85       400\n",
      "\n",
      "Cost: 100.0\n",
      "Gamma: 0.04544897959183674\n",
      "Score: 0.5021354484441732\n",
      "\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.90      0.96      0.93       360\n",
      "          1       0.13      0.05      0.07        40\n",
      "\n",
      "avg / total       0.82      0.87      0.85       400\n",
      "\n",
      "Cost: 100.0\n",
      "Gamma: 0.047469387755102045\n",
      "Score: 0.5021354484441732\n",
      "\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.90      0.96      0.93       360\n",
      "          1       0.13      0.05      0.07        40\n",
      "\n",
      "avg / total       0.82      0.87      0.85       400\n",
      "\n",
      "Cost: 100.0\n",
      "Gamma: 0.04948979591836735\n",
      "Score: 0.5021354484441732\n",
      "\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.90      0.96      0.93       360\n",
      "          1       0.13      0.05      0.07        40\n",
      "\n",
      "avg / total       0.82      0.87      0.85       400\n",
      "\n",
      "Cost: 100.0\n",
      "Gamma: 0.051510204081632656\n",
      "Score: 0.5021354484441732\n",
      "\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.90      0.96      0.93       360\n",
      "          1       0.13      0.05      0.07        40\n",
      "\n",
      "avg / total       0.82      0.87      0.85       400\n",
      "\n",
      "Cost: 100.0\n",
      "Gamma: 0.05353061224489796\n",
      "Score: 0.5021354484441732\n",
      "\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.90      0.96      0.93       360\n",
      "          1       0.13      0.05      0.07        40\n",
      "\n",
      "avg / total       0.82      0.87      0.85       400\n",
      "\n",
      "Cost: 100.0\n",
      "Gamma: 0.05555102040816327\n",
      "Score: 0.5021354484441732\n",
      "\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.90      0.96      0.93       360\n",
      "          1       0.13      0.05      0.07        40\n",
      "\n",
      "avg / total       0.82      0.87      0.85       400\n",
      "\n",
      "Cost: 100.0\n",
      "Gamma: 0.05757142857142858\n",
      "Score: 0.5021354484441732\n",
      "\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.90      0.96      0.93       360\n",
      "          1       0.13      0.05      0.07        40\n",
      "\n",
      "avg / total       0.82      0.87      0.85       400\n",
      "\n",
      "Cost: 100.0\n",
      "Gamma: 0.059591836734693884\n",
      "Score: 0.5049379909575409\n",
      "\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.90      0.97      0.93       360\n",
      "          1       0.15      0.05      0.08        40\n",
      "\n",
      "avg / total       0.83      0.88      0.85       400\n",
      "\n",
      "Cost: 100.0\n",
      "Gamma: 0.06161224489795919\n",
      "Score: 0.5049379909575409\n",
      "\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.90      0.97      0.93       360\n",
      "          1       0.15      0.05      0.08        40\n",
      "\n",
      "avg / total       0.83      0.88      0.85       400\n",
      "\n",
      "Cost: 100.0\n",
      "Gamma: 0.0636326530612245\n",
      "Score: 0.5049379909575409\n",
      "\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.90      0.97      0.93       360\n",
      "          1       0.15      0.05      0.08        40\n",
      "\n",
      "avg / total       0.83      0.88      0.85       400\n",
      "\n",
      "Cost: 100.0\n",
      "Gamma: 0.0656530612244898\n",
      "Score: 0.5093333333333333\n",
      "\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.90      0.98      0.94       360\n",
      "          1       0.20      0.05      0.08        40\n",
      "\n",
      "avg / total       0.83      0.89      0.85       400\n",
      "\n",
      "Cost: 100.0\n",
      "Gamma: 0.0676734693877551\n",
      "Score: 0.5093333333333333\n",
      "\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.90      0.98      0.94       360\n",
      "          1       0.20      0.05      0.08        40\n",
      "\n",
      "avg / total       0.83      0.89      0.85       400\n",
      "\n",
      "Cost: 100.0\n",
      "Gamma: 0.06969387755102041\n",
      "Score: 0.5108562732682953\n",
      "\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.90      0.98      0.94       360\n",
      "          1       0.22      0.05      0.08        40\n",
      "\n",
      "avg / total       0.83      0.89      0.85       400\n",
      "\n",
      "Cost: 100.0\n",
      "Gamma: 0.07171428571428572\n",
      "Score: 0.5108562732682953\n",
      "\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.90      0.98      0.94       360\n",
      "          1       0.22      0.05      0.08        40\n",
      "\n",
      "avg / total       0.83      0.89      0.85       400\n",
      "\n",
      "Cost: 100.0\n",
      "Gamma: 0.07373469387755102\n",
      "Score: 0.5108562732682953\n",
      "\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.90      0.98      0.94       360\n",
      "          1       0.22      0.05      0.08        40\n",
      "\n",
      "avg / total       0.83      0.89      0.85       400\n",
      "\n",
      "Cost: 100.0\n",
      "Gamma: 0.07575510204081633\n",
      "Score: 0.5108562732682953\n",
      "\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.90      0.98      0.94       360\n",
      "          1       0.22      0.05      0.08        40\n",
      "\n",
      "avg / total       0.83      0.89      0.85       400\n",
      "\n",
      "Cost: 100.0\n",
      "Gamma: 0.07777551020408163\n",
      "Score: 0.5108562732682953\n",
      "\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.90      0.98      0.94       360\n",
      "          1       0.22      0.05      0.08        40\n",
      "\n",
      "avg / total       0.83      0.89      0.85       400\n",
      "\n",
      "Cost: 100.0\n",
      "Gamma: 0.07979591836734694\n",
      "Score: 0.5108562732682953\n",
      "\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.90      0.98      0.94       360\n",
      "          1       0.22      0.05      0.08        40\n",
      "\n",
      "avg / total       0.83      0.89      0.85       400\n",
      "\n",
      "Cost: 100.0\n",
      "Gamma: 0.08181632653061224\n",
      "Score: 0.5108562732682953\n",
      "\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.90      0.98      0.94       360\n",
      "          1       0.22      0.05      0.08        40\n",
      "\n",
      "avg / total       0.83      0.89      0.85       400\n",
      "\n",
      "Cost: 100.0\n",
      "Gamma: 0.08383673469387756\n",
      "Score: 0.5108562732682953\n",
      "\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.90      0.98      0.94       360\n",
      "          1       0.22      0.05      0.08        40\n",
      "\n",
      "avg / total       0.83      0.89      0.85       400\n",
      "\n",
      "Cost: 100.0\n",
      "Gamma: 0.08585714285714287\n",
      "Score: 0.5108562732682953\n",
      "\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.90      0.98      0.94       360\n",
      "          1       0.22      0.05      0.08        40\n",
      "\n",
      "avg / total       0.83      0.89      0.85       400\n",
      "\n",
      "Cost: 100.0\n",
      "Gamma: 0.08787755102040817\n",
      "Score: 0.5108562732682953\n",
      "\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.90      0.98      0.94       360\n",
      "          1       0.22      0.05      0.08        40\n",
      "\n",
      "avg / total       0.83      0.89      0.85       400\n",
      "\n",
      "Cost: 100.0\n",
      "Gamma: 0.08989795918367348\n",
      "Score: 0.5108562732682953\n",
      "\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.90      0.98      0.94       360\n",
      "          1       0.22      0.05      0.08        40\n",
      "\n",
      "avg / total       0.83      0.89      0.85       400\n",
      "\n",
      "Cost: 100.0\n",
      "Gamma: 0.09191836734693878\n",
      "Score: 0.5108562732682953\n",
      "\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.90      0.98      0.94       360\n",
      "          1       0.22      0.05      0.08        40\n",
      "\n",
      "avg / total       0.83      0.89      0.85       400\n",
      "\n",
      "Cost: 100.0\n",
      "Gamma: 0.09393877551020409\n",
      "Score: 0.5108562732682953\n",
      "\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.90      0.98      0.94       360\n",
      "          1       0.22      0.05      0.08        40\n",
      "\n",
      "avg / total       0.83      0.89      0.85       400\n",
      "\n",
      "Cost: 100.0\n",
      "Gamma: 0.0959591836734694\n",
      "Score: 0.5108562732682953\n",
      "\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.90      0.98      0.94       360\n",
      "          1       0.22      0.05      0.08        40\n",
      "\n",
      "avg / total       0.83      0.89      0.85       400\n",
      "\n",
      "Cost: 100.0\n",
      "Gamma: 0.0979795918367347\n",
      "Score: 0.5108562732682953\n",
      "\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.90      0.98      0.94       360\n",
      "          1       0.22      0.05      0.08        40\n",
      "\n",
      "avg / total       0.83      0.89      0.85       400\n",
      "\n",
      "Cost: 100.0\n",
      "Gamma: 0.1\n",
      "Score: 0.5108562732682953\n",
      "\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.90      0.98      0.94       360\n",
      "          1       0.22      0.05      0.08        40\n",
      "\n",
      "avg / total       0.83      0.89      0.85       400\n",
      "\n"
     ]
    }
   ],
   "source": [
    "make_model(labels, features, 'svm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
